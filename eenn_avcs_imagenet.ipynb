{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 11:00:18.729814: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-27 11:00:19.278377: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mona/anaconda3/envs/laplace/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils_eenn_avcs import *\n",
    "\n",
    "import robustness_metrics as rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'ImageNet.p', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "logits, targets, ARGS = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "L, N, C = logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.softmax(logits, dim=2)\n",
    "preds = get_preds_per_exit(probs)\n",
    "acc = get_acc_per_exit(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.5663),\n",
       " tensor(0.6514),\n",
       " tensor(0.6842),\n",
       " tensor(0.6977),\n",
       " tensor(0.7134)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 11:00:34.900323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22036 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function KerasMetric._add_prediction at 0x7fe89402e9d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "eces = []\n",
    "\n",
    "L = len(acc)\n",
    "for l in range(L):\n",
    "    ece = rm.metrics.ExpectedCalibrationError(num_bins=15)\n",
    "    ece.add_batch(probs[l, :, :].numpy(), label=targets.numpy())\n",
    "    eces.append(ece.result()['ece'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.013025594875216484,\n",
       " 0.010537293739616871,\n",
       " 0.009827039204537868,\n",
       " 0.008983026258647442,\n",
       " 0.021733099594712257]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Temperaturce scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = torch.randperm(N)\n",
    "\n",
    "# Split indices into two groups\n",
    "indices1, indices2 = indices[:int(N / 2)], indices[int(N / 2):]\n",
    "\n",
    "logits_val = logits.index_select(1, indices1)\n",
    "logits_test = logits.index_select(1, indices2)\n",
    "\n",
    "targets_val = targets.index_select(0, indices1)\n",
    "targets_test = targets.index_select(0, indices2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_arr = [0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 1., 1.1, 1.25, 1.5, 1.75, 2., 2.25, 2.5, 5., 10.]\n",
    "\n",
    "ECE_dict = {}\n",
    "for T in T_arr:\n",
    "    logits_temper = logits_val / T\n",
    "    probs_temp = torch.softmax(logits_temper, dim=2)\n",
    "    eces = []\n",
    "    for l in range(L):\n",
    "        ece = rm.metrics.ExpectedCalibrationError(num_bins=15)\n",
    "        ece.add_batch(probs_temp[l, :, :].numpy(), label=targets_val.numpy())\n",
    "        eces.append(ece.result()['ece'])\n",
    "    ECE_dict[T] = eces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_star = []\n",
    "for l in range(L):\n",
    "    ECE_min, T_min = 1e10, None\n",
    "    for T in ECE_dict.keys():\n",
    "        if ECE_dict[T][l] < ECE_min:\n",
    "            ECE_min = ECE_dict[T][l]\n",
    "            T_min = T\n",
    "    T_star.append(T_min)\n",
    "\n",
    "T_star = torch.tensor(T_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.1000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MSDNet for ImageNet seems well calibrated already, optimal temperature at most extis is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Credible sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "L, N, C = probs.shape\n",
    "probs_num = probs.numpy()\n",
    "\n",
    "cred_sets = []\n",
    "for n in range(N):\n",
    "    cred_sets_n = []\n",
    "    for l in range(L):\n",
    "        sorted_classes = np.argsort(probs_num[l, n])[::-1]\n",
    "        cum_sum = np.cumsum(probs_num[l, n, sorted_classes])\n",
    "        num_classes_to_include = np.where(cum_sum >= 1 - alpha)[0][0] + 1\n",
    "        cred_sets_n.append(sorted_classes[:num_classes_to_include].tolist())\n",
    "    cred_sets.append(cred_sets_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cred_sets_intersect = []\n",
    "for i in range(N):\n",
    "    cred_sets_intersect.append(running_intersection_classification(cred_sets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes_cred = []\n",
    "coverage_cred = []\n",
    "for i in range(N):\n",
    "    sizes_cred.append([len(cred_sets[i][l]) for l in range(L)])\n",
    "    coverage_cred.append([targets[i] in cred_sets[i][l] for l in range(L)])\n",
    "\n",
    "consistency_cred = np.array([consistency_classifciation(cred_sets[i]) for i in range(N)])\n",
    "sizes_cred = np.array(sizes_cred)\n",
    "coverage_cred = np.array(coverage_cred)\n",
    "\n",
    "sizes_cred_intersect = []\n",
    "coverage_cred_intersect = []\n",
    "for i in range(N):\n",
    "    sizes_cred_intersect.append([len(cred_sets_intersect[i][l]) for l in range(L)])\n",
    "    coverage_cred_intersect.append([targets[i] in cred_sets_intersect[i][l] for l in range(L)])\n",
    "\n",
    "consistency_cred_intersect = np.array([consistency_classifciation(cred_sets_intersect[i]) for i in range(N)])\n",
    "sizes_cred_intersect = np.array(sizes_cred_intersect)\n",
    "coverage_cred_intersect = np.array(coverage_cred_intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([43.6209 , 27.93284, 22.82906, 19.85656, 18.32186]),\n",
       " array([66.71544037, 53.34832452, 48.2882818 , 43.03334132, 42.71981351]),\n",
       " array([43.6209 , 18.6902 , 11.92742,  9.168  ,  7.60886]),\n",
       " array([66.71544037, 34.72678136, 24.40029574, 19.33324536, 16.71180749]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes_cred.mean(axis=0), sizes_cred.std(axis=0), sizes_cred_intersect.mean(axis=0), sizes_cred_intersect.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.9495 , 0.95552, 0.95732, 0.95792, 0.95582]),\n",
       " array([0.9495 , 0.93166, 0.9211 , 0.91474, 0.90846]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coverage_cred.mean(axis=0), coverage_cred_intersect.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.        , 0.83629903, 0.77660886, 0.73972643, 0.7565029 ]),\n",
       " array([0.        , 0.21893355, 0.26666782, 0.28745661, 0.29318572]),\n",
       " array([1., 1., 1., 1., 1.]),\n",
       " array([0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consistency_cred.mean(axis=0), consistency_cred.std(axis=0), consistency_cred_intersect.mean(axis=0), consistency_cred_intersect.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laplace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
